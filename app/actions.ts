"use server";

import OpenAI from "openai";
import * as Sentry from "@sentry/nextjs";
import { ContractAnalysisError } from "@/lib/errors";
import { splitIntoChunks } from "@/lib/text-utils";
import { 
  trackAnalysisComplete,
  trackChunkProcessing,
  trackAnalysisError 
} from "@/lib/analytics-events";

// ... (existing interfaces and configs)

async function analyzeChunk(
  chunk: string,
  chunkIndex: number,
  totalChunks: number
): Promise<AnalysisResult> {
  const chunkStartTime = Date.now();
  
  try {
    console.log(`Starting analysis of chunk ${chunkIndex + 1}/${totalChunks}`);
    
    const systemPrompt = "You are a legal expert. Analyze this contract section concisely.";
    const userPrompt = `Section ${chunkIndex + 1}/${totalChunks}:\n${chunk}\n\nProvide JSON with: summary (brief), keyTerms, potentialRisks, importantClauses, recommendations.`;

    console.log(`Making API call for chunk ${chunkIndex + 1}`);
    const response = await withRetry(async () => {
      return await openai.chat.completions.create({
        model: "gpt-3.5-turbo-1106",
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: userPrompt },
        ],
        temperature: 0.3,
        max_tokens: 1000,
        response_format: { type: "json_object" },
      });
    });

    const content = response.choices[0]?.message?.content;
    if (!content) {
      console.error(`No content in response for chunk ${chunkIndex + 1}:`, response);
      throw new ContractAnalysisError(
        'No analysis generated by AI model',
        'API_ERROR'
      );
    }

    console.log(`Parsing response for chunk ${chunkIndex + 1}`);
    try {
      const result = JSON.parse(content) as AnalysisResult;
      // Validate the result structure
      const requiredFields = ['summary', 'keyTerms', 'potentialRisks', 'importantClauses'];
      const missingFields = requiredFields.filter(field => !(field in result));
      
      if (missingFields.length > 0) {
        console.error(`Missing fields in chunk ${chunkIndex + 1} response:`, missingFields);
        throw new ContractAnalysisError(
          `Invalid response format: missing fields ${missingFields.join(', ')}`,
          'API_ERROR'
        );
      }

      // Track chunk processing time
      const processingTime = Date.now() - chunkStartTime;
      trackChunkProcessing(chunkIndex + 1, totalChunks, processingTime);
      
      return result;
    } catch (error) {
      console.error(`Failed to parse chunk ${chunkIndex + 1} response:`, {
        error,
        content,
      });

      Sentry.captureException(error, {
        extra: {
          chunkIndex,
          totalChunks,
          content: content.substring(0, 1000),
        },
      });

      throw new ContractAnalysisError(
        'Failed to parse AI model response',
        'API_ERROR',
        error
      );
    }
  } catch (error) {
    console.error(`Error in analyzeChunk ${chunkIndex + 1}:`, error);
    
    Sentry.captureException(error, {
      extra: {
        chunkIndex,
        totalChunks,
      },
    });

    if (error instanceof ContractAnalysisError) {
      throw error;
    }
    throw new ContractAnalysisError(
      `Failed to analyze chunk ${chunkIndex + 1}`,
      'API_ERROR',
      error
    );
  }
}

export async function analyzeContract(formData: FormData) {
  const analysisStartTime = Date.now();
  let fileName = '';
  
  try {
    console.log('Starting contract analysis');

    // Add context for this analysis session
    fileName = formData.get("filename")?.toString() || '';
    Sentry.setContext("contract", {
      filename: fileName,
      timestamp: new Date().toISOString(),
    });
    
    // Validate OpenAI API key
    if (!process.env.OPENAI_API_KEY) {
      console.error('OpenAI API key not configured');
      trackAnalysisError('CONFIGURATION', 'OpenAI API key not configured', 'unknown');
      throw new ContractAnalysisError(
        "OpenAI API key is not configured",
        "CONFIGURATION_ERROR"
      );
    }

    // Get and validate text content
    const text = formData.get("text");
    if (!text || typeof text !== 'string') {
      console.error('Invalid text content:', { text });
      trackAnalysisError('VALIDATION', 'Invalid or missing text content', 'unknown');
      throw new ContractAnalysisError(
        "No text content received",
        "INVALID_INPUT"
      );
    }
    if (text.length === 0) {
      console.error('Empty text content');
      trackAnalysisError('VALIDATION', 'Empty text content', 'unknown');
      throw new ContractAnalysisError(
        "Empty document content",
        "INVALID_INPUT"
      );
    }

    // Split the content into manageable chunks
    console.log('Splitting text into chunks');
    const chunks = splitIntoChunks(text);
    if (chunks.length === 0) {
      console.error('No chunks created from text');
      trackAnalysisError('PROCESSING', 'Text splitting failed - no chunks created', 'unknown');
      throw new ContractAnalysisError(
        "Document content is too short",
        "INVALID_INPUT"
      );
    }
    console.log(`Split contract into ${chunks.length} chunks`);
    
    // Add context about the analysis scope
    Sentry.setContext("analysis", {
      chunkCount: chunks.length,
      textLength: text.length,
    });

    // Analyze each chunk
    console.log('Starting chunk analysis');
    const analysisResults = await Promise.all(
      chunks.map((chunk, index) => analyzeChunk(chunk, index, chunks.length))
    );

    // Merge the results
    console.log('Merging analysis results');
    const mergedAnalysis = mergeAnalysisResults(analysisResults);

    // Calculate total processing time
    const processingTime = Date.now() - analysisStartTime;

    // Track successful completion
    trackAnalysisComplete(
      fileName.endsWith('.pdf') ? 'pdf' : 'docx',
      processingTime,
      chunks.length
    );

    // Add metadata and return
    return {
      ...mergedAnalysis,
      metadata: {
        analyzedAt: new Date().toISOString(),
        documentName: fileName,
        modelVersion: "gpt-3.5-turbo-1106",
        totalChunks: chunks.length
      } as AnalysisMetadata,
    };
  } catch (error) {
    console.error("Error generating analysis:", error);

    // Track analysis error
    if (error instanceof ContractAnalysisError) {
      trackAnalysisError(
        error.code,
        error.message,
        fileName.endsWith('.pdf') ? 'pdf' : 'docx'
      );
    } else if (error instanceof OpenAI.APIError) {
      trackAnalysisError(
        'OPENAI_API',
        `${error.type}: ${error.message}`,
        fileName.endsWith('.pdf') ? 'pdf' : 'docx'
      );
    } else {
      trackAnalysisError(
        'UNKNOWN',
        error instanceof Error ? error.message : 'Unknown error',
        fileName.endsWith('.pdf') ? 'pdf' : 'docx'
      );
    }

    Sentry.captureException(error, {
      extra: {
        filename: fileName,
        textLength: formData.get("text")?.toString().length,
      },
    });
    
    if (error instanceof ContractAnalysisError) {
      throw error;
    }
    
    if (error instanceof OpenAI.APIError) {
      console.error('OpenAI API error:', {
        status: error.status,
        message: error.message,
        type: error.type,
      });
      throw new ContractAnalysisError(
        `OpenAI API error: ${error.message}`,
        'API_ERROR',
        error
      );
    }

    console.error('Unknown error:', error);
    throw new ContractAnalysisError(
      `Failed to analyze contract: ${error instanceof Error ? error.message : 'Unknown error'}`,
      'UNKNOWN_ERROR',
      error
    );
  }
}