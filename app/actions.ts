"use server";

import OpenAI from "openai";
import * as Sentry from "@sentry/nextjs";
import { ContractAnalysisError } from "@/lib/errors";
import { splitIntoChunks } from "@/lib/text-utils";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

interface AnalysisResult {
  summary: string;
  keyTerms: string[];
  potentialRisks: string[];
  importantClauses: string[];
  recommendations?: string[];
}

interface AnalysisMetadata {
  analyzedAt: string;
  documentName: string;
  modelVersion: string;
  totalChunks?: number;
  currentChunk?: number;
}

async function withRetry<T>(fn: () => Promise<T>, maxAttempts = 3): Promise<T> {
  let lastError: unknown;
  
  for (let attempt = 1; attempt <= maxAttempts; attempt++) {
    try {
      return await fn();
    } catch (error) {
      console.error(`Retry attempt ${attempt} failed:`, error);
      lastError = error;
      
      if (attempt === maxAttempts) break;
      
      await new Promise((resolve) => 
        setTimeout(resolve, Math.pow(2, attempt - 1) * 1000)
      );
    }
  }
  
  throw lastError;
}

async function analyzeChunk(
  chunk: string,
  chunkIndex: number,
  totalChunks: number
): Promise<AnalysisResult> {
  try {
    console.log(`Starting analysis of chunk ${chunkIndex + 1}/${totalChunks}`);
    
    const systemPrompt = "You are a legal expert. Analyze this contract section concisely.";
    const userPrompt = `Section ${chunkIndex + 1}/${totalChunks}:\n${chunk}\n\nProvide JSON with: summary (brief), keyTerms, potentialRisks, importantClauses, recommendations.`;

    console.log(`Making API call for chunk ${chunkIndex + 1}`);
    const response = await withRetry(async () => {
      return await openai.chat.completions.create({
        model: "gpt-3.5-turbo-1106",
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: userPrompt },
        ],
        temperature: 0.3,
        max_tokens: 1000,
        response_format: { type: "json_object" },
      });
    });

    const content = response.choices[0]?.message?.content;
    if (!content) {
      throw new ContractAnalysisError(
        'No analysis generated by AI model',
        'API_ERROR'
      );
    }

    return JSON.parse(content) as AnalysisResult;
  } catch (error) {
    console.error(`Error in analyzeChunk ${chunkIndex + 1}:`, error);
    throw error;
  }
}

function mergeAnalysisResults(results: AnalysisResult[]): AnalysisResult {
  if (!Array.isArray(results) || results.length === 0) {
    throw new ContractAnalysisError(
      'No analysis results to merge',
      'TEXT_PROCESSING_ERROR'
    );
  }

  const merged: AnalysisResult = {
    summary: "",
    keyTerms: [],
    potentialRisks: [],
    importantClauses: [],
    recommendations: [],
  };

  results.forEach(result => {
    if (Array.isArray(result.keyTerms)) merged.keyTerms.push(...result.keyTerms);
    if (Array.isArray(result.potentialRisks)) merged.potentialRisks.push(...result.potentialRisks);
    if (Array.isArray(result.importantClauses)) merged.importantClauses.push(...result.importantClauses);
    if (Array.isArray(result.recommendations)) merged.recommendations?.push(...result.recommendations);
  });

  merged.keyTerms = Array.from(new Set(merged.keyTerms));
  merged.potentialRisks = Array.from(new Set(merged.potentialRisks));
  merged.importantClauses = Array.from(new Set(merged.importantClauses));
  if (merged.recommendations) {
    merged.recommendations = Array.from(new Set(merged.recommendations));
  }

  merged.summary = `This contract analysis is based on ${results.length} sections. ` + 
    (results[0]?.summary || 'No summary available.');

  return merged;
}

// Track the state of ongoing analyses
const analysisState = new Map<string, {
  results: AnalysisResult[];
  currentChunk: number;
  totalChunks: number;
}>();

export async function analyzeContract(formData: FormData) {
  try {
    console.log('Processing contract analysis request');
    
    const text = formData.get("text");
    const filename = formData.get("filename");

    if (!text || typeof text !== 'string' || !filename || typeof filename !== 'string') {
      throw new ContractAnalysisError("Invalid input", "INVALID_INPUT");
    }

    const stateKey = `${filename}-${text.length}`;
    let state = analysisState.get(stateKey);

    // Initialize new analysis if needed
    if (!state) {
      const chunks = splitIntoChunks(text);
      if (chunks.length === 0) {
        throw new ContractAnalysisError("Document too short", "INVALID_INPUT");
      }

      state = {
        results: [],
        currentChunk: 0,
        totalChunks: chunks.length,
      };
      analysisState.set(stateKey, state);

      // Process first chunk
      const result = await analyzeChunk(chunks[0], 0, chunks.length);
      state.results.push(result);
      state.currentChunk = 1;

      // Start background processing of remaining chunks
      (async () => {
        try {
          for (let i = 1; i < chunks.length; i++) {
            const result = await analyzeChunk(chunks[i], i, chunks.length);
            state.results.push(result);
            state.currentChunk = i + 1;
          }
        } catch (error) {
          console.error('Background processing error:', error);
        }
      })();
    }

    // Return current state
    const analysis = state.results.length > 0 ? mergeAnalysisResults(state.results) : {
      summary: "Starting analysis...",
      keyTerms: [],
      potentialRisks: [],
      importantClauses: [],
      recommendations: []
    };

    const response = {
      ...analysis,
      metadata: {
        analyzedAt: new Date().toISOString(),
        documentName: filename,
        modelVersion: "gpt-3.5-turbo-1106",
        totalChunks: state.totalChunks,
        currentChunk: state.currentChunk
      }
    };

    // Clean up if analysis is complete
    if (state.currentChunk === state.totalChunks) {
      analysisState.delete(stateKey);
    }

    return response;

  } catch (error) {
    console.error("Error in analyzeContract:", error);
    throw error;
  }
}