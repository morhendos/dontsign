"use server";

import OpenAI from "openai";
import * as Sentry from "@sentry/nextjs";
import { ContractAnalysisError } from "@/lib/errors";
import { splitIntoChunks } from "@/lib/text-utils";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

interface AnalysisResult {
  summary: string;
  keyTerms: string[];
  potentialRisks: string[];
  importantClauses: string[];
  recommendations?: string[];
}

interface AnalysisMetadata {
  analyzedAt: string;
  documentName: string;
  modelVersion: string;
  totalChunks?: number;
}

type ProgressCallback = (currentChunk: number, totalChunks: number) => void;

// Add retry logic for API failures
async function withRetry<T>(fn: () => Promise<T>, maxAttempts = 3): Promise<T> {
  let lastError: unknown;
  
  for (let attempt = 1; attempt <= maxAttempts; attempt++) {
    try {
      return await fn();
    } catch (error) {
      console.error(`Retry attempt ${attempt} failed:`, error);
      lastError = error;
      
      if (attempt === maxAttempts) break;
      
      // Exponential backoff
      await new Promise((resolve) => 
        setTimeout(resolve, Math.pow(2, attempt - 1) * 1000)
      );
    }
  }
  
  throw lastError;
}

// Function to analyze a single chunk
async function analyzeChunk(
  chunk: string,
  chunkIndex: number,
  totalChunks: number,
  onProgress?: ProgressCallback
): Promise<AnalysisResult> {
  try {
    console.log(`Starting analysis of chunk ${chunkIndex + 1}/${totalChunks}`);
    
    const systemPrompt = "You are a legal expert. Analyze this contract section concisely.";
    const userPrompt = `Section ${chunkIndex + 1}/${totalChunks}:\n${chunk}\n\nProvide JSON with: summary (brief), keyTerms, potentialRisks, importantClauses, recommendations.`;

    console.log(`Making API call for chunk ${chunkIndex + 1}`);
    const response = await withRetry(async () => {
      return await openai.chat.completions.create({
        model: "gpt-3.5-turbo-1106",
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: userPrompt },
        ],
        temperature: 0.3,
        max_tokens: 1000,
        response_format: { type: "json_object" },
      });
    });

    // Update progress after successful analysis
    onProgress?.(chunkIndex, totalChunks);

    const content = response.choices[0]?.message?.content;
    if (!content) {
      throw new ContractAnalysisError(
        'No analysis generated by AI model',
        'API_ERROR'
      );
    }

    try {
      const result = JSON.parse(content) as AnalysisResult;
      // Validate the result structure
      const requiredFields = ['summary', 'keyTerms', 'potentialRisks', 'importantClauses'];
      const missingFields = requiredFields.filter(field => !(field in result));
      
      if (missingFields.length > 0) {
        throw new ContractAnalysisError(
          `Invalid response format: missing fields ${missingFields.join(', ')}`,
          'API_ERROR'
        );
      }
      
      return result;
    } catch (error) {
      throw new ContractAnalysisError(
        'Failed to parse AI model response',
        'API_ERROR',
        error
      );
    }
  } catch (error) {
    console.error(`Error in analyzeChunk ${chunkIndex + 1}:`, error);
    throw error;
  }
}

// Main analysis function
export async function analyzeContract(
  formData: FormData,
  onProgress?: ProgressCallback
) {
  try {
    console.log('Starting contract analysis');
    
    // Add context for this analysis session
    Sentry.setContext("contract", {
      filename: formData.get("filename"),
      timestamp: new Date().toISOString(),
    });
    
    // Validate OpenAI API key
    if (!process.env.OPENAI_API_KEY) {
      throw new ContractAnalysisError(
        "OpenAI API key is not configured",
        "CONFIGURATION_ERROR"
      );
    }

    // Get and validate text content
    const text = formData.get("text");
    if (!text || typeof text !== 'string') {
      throw new ContractAnalysisError(
        "No text content received",
        "INVALID_INPUT"
      );
    }
    if (text.length === 0) {
      throw new ContractAnalysisError(
        "Empty document content",
        "INVALID_INPUT"
      );
    }

    // Get and validate filename
    const filename = formData.get("filename");
    if (!filename || typeof filename !== 'string') {
      throw new ContractAnalysisError(
        "No filename received",
        "INVALID_INPUT"
      );
    }

    // Split the content into manageable chunks
    console.log('Splitting text into chunks');
    const chunks = splitIntoChunks(text);
    if (chunks.length === 0) {
      throw new ContractAnalysisError(
        "Document content is too short",
        "INVALID_INPUT"
      );
    }
    console.log(`Split contract into ${chunks.length} chunks`);

    // Initialize progress
    onProgress?.(0, chunks.length);
    
    // Add context about the analysis scope
    Sentry.setContext("analysis", {
      chunkCount: chunks.length,
      textLength: text.length,
    });

    // Analyze chunks sequentially to ensure order and show progress
    const analysisResults: AnalysisResult[] = [];
    for (let i = 0; i < chunks.length; i++) {
      const result = await analyzeChunk(chunks[i], i, chunks.length, onProgress);
      analysisResults.push(result);
    }

    // Merge results
    console.log('Merging analysis results');
    const mergedAnalysis = mergeAnalysisResults(analysisResults);

    // Add metadata
    console.log('Adding metadata to results');
    return {
      ...mergedAnalysis,
      metadata: {
        analyzedAt: new Date().toISOString(),
        documentName: filename,
        modelVersion: "gpt-3.5-turbo-1106",
        totalChunks: chunks.length
      } as AnalysisMetadata,
    };
  } catch (error) {
    console.error("Error generating analysis:", error);

    // Track the error in Sentry with context
    Sentry.captureException(error, {
      extra: {
        filename: formData.get("filename"),
        textLength: formData.get("text")?.toString().length,
      },
    });
    
    // Handle known errors
    if (error instanceof ContractAnalysisError) {
      throw error;
    }
    
    // Handle OpenAI API errors
    if (error instanceof OpenAI.APIError) {
      throw new ContractAnalysisError(
        `OpenAI API error: ${error.message}`,
        'API_ERROR',
        error
      );
    }

    // Handle unknown errors
    throw new ContractAnalysisError(
      `Failed to analyze contract: ${error instanceof Error ? error.message : 'Unknown error'}`,
      'UNKNOWN_ERROR',
      error
    );
  }
}

// Function to merge analysis results
function mergeAnalysisResults(results: AnalysisResult[]): AnalysisResult {
  if (!Array.isArray(results) || results.length === 0) {
    throw new ContractAnalysisError(
      'No analysis results to merge',
      'TEXT_PROCESSING_ERROR'
    );
  }

  const merged: AnalysisResult = {
    summary: "",
    keyTerms: [],
    potentialRisks: [],
    importantClauses: [],
    recommendations: [],
  };

  // Merge all arrays and remove duplicates
  results.forEach(result => {
    if (Array.isArray(result.keyTerms)) merged.keyTerms.push(...result.keyTerms);
    if (Array.isArray(result.potentialRisks)) merged.potentialRisks.push(...result.potentialRisks);
    if (Array.isArray(result.importantClauses)) merged.importantClauses.push(...result.importantClauses);
    if (Array.isArray(result.recommendations)) merged.recommendations?.push(...result.recommendations);
  });

  // Remove duplicates
  merged.keyTerms = Array.from(new Set(merged.keyTerms));
  merged.potentialRisks = Array.from(new Set(merged.potentialRisks));
  merged.importantClauses = Array.from(new Set(merged.importantClauses));
  if (merged.recommendations) {
    merged.recommendations = Array.from(new Set(merged.recommendations));
  }

  // Create comprehensive summary
  merged.summary = `This contract analysis is based on ${results.length} sections. ` + 
    (results[0]?.summary || 'No summary available.');

  return merged;
}