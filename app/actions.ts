"use server";

import OpenAI from "openai";
import * as Sentry from "@sentry/nextjs";
import { ContractAnalysisError } from "@/lib/errors";
import { splitIntoChunks } from "@/lib/text-utils";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

interface AnalysisResult {
  summary: string;
  keyTerms: string[];
  potentialRisks: string[];
  importantClauses: string[];
  recommendations?: string[];
}

interface AnalysisMetadata {
  analyzedAt: string;
  documentName: string;
  modelVersion: string;
  totalChunks?: number;
}

async function withRetry<T>(fn: () => Promise<T>, maxAttempts = 3): Promise<T> {
  let lastError: unknown;
  
  for (let attempt = 1; attempt <= maxAttempts; attempt++) {
    try {
      return await fn();
    } catch (error) {
      console.error(`Retry attempt ${attempt} failed:`, error);
      lastError = error;
      
      Sentry.addBreadcrumb({
        category: 'retry',
        message: `API retry attempt ${attempt} failed`,
        level: 'warning',
      });
      
      if (attempt === maxAttempts) break;
      await new Promise((resolve) => setTimeout(resolve, Math.pow(2, attempt - 1) * 1000));
    }
  }
  
  throw new ContractAnalysisError(
    'Maximum retry attempts reached',
    'API_ERROR',
    lastError
  );
}

async function analyzeChunk(
  chunk: string,
  chunkIndex: number,
  totalChunks: number
): Promise<AnalysisResult> {
  const chunkTransaction = Sentry.startTransaction({
    name: 'analyze_chunk',
    op: 'ai.analyze',
    data: { chunkIndex, totalChunks },
  });

  try {
    Sentry.addBreadcrumb({
      category: 'analysis',
      message: `Analyzing chunk ${chunkIndex + 1}/${totalChunks}`,
      level: 'info',
    });

    const response = await withRetry(async () => {
      return await openai.chat.completions.create({
        model: "gpt-3.5-turbo-1106",
        messages: [
          { role: "system", content: "You are a legal expert. Analyze this contract section concisely." },
          { role: "user", content: `Section ${chunkIndex + 1}/${totalChunks}:\n${chunk}\n\nProvide JSON with: summary (brief), keyTerms, potentialRisks, importantClauses, recommendations.` },
        ],
        temperature: 0.3,
        max_tokens: 1000,
        response_format: { type: "json_object" },
      });
    });

    const content = response.choices[0]?.message?.content;
    if (!content) {
      throw new ContractAnalysisError('No analysis generated by AI model', 'API_ERROR');
    }

    const result = JSON.parse(content) as AnalysisResult;
    const requiredFields = ['summary', 'keyTerms', 'potentialRisks', 'importantClauses'];
    const missingFields = requiredFields.filter(field => !(field in result));
    
    if (missingFields.length > 0) {
      throw new ContractAnalysisError(
        `Invalid response format: missing fields ${missingFields.join(', ')}`,
        'API_ERROR'
      );
    }
    
    return result;
  } catch (error) {
    Sentry.captureException(error, {
      extra: { chunkIndex, totalChunks },
    });
    throw error instanceof ContractAnalysisError ? error : 
      new ContractAnalysisError(`Failed to analyze chunk ${chunkIndex + 1}`, 'API_ERROR', error);
  } finally {
    chunkTransaction.finish();
  }
}

function mergeAnalysisResults(results: AnalysisResult[]): AnalysisResult {
  const mergeTransaction = Sentry.startTransaction({
    name: 'merge_results',
    op: 'analysis.merge',
    data: { resultCount: results.length },
  });

  try {
    if (!Array.isArray(results) || results.length === 0) {
      throw new ContractAnalysisError('No analysis results to merge', 'TEXT_PROCESSING_ERROR');
    }

    const merged: AnalysisResult = {
      summary: "",
      keyTerms: [],
      potentialRisks: [],
      importantClauses: [],
      recommendations: [],
    };

    results.forEach(result => {
      if (!result || typeof result !== 'object') {
        throw new ContractAnalysisError('Invalid analysis result format', 'TEXT_PROCESSING_ERROR');
      }

      if (Array.isArray(result.keyTerms)) merged.keyTerms.push(...result.keyTerms);
      if (Array.isArray(result.potentialRisks)) merged.potentialRisks.push(...result.potentialRisks);
      if (Array.isArray(result.importantClauses)) merged.importantClauses.push(...result.importantClauses);
      if (Array.isArray(result.recommendations)) merged.recommendations?.push(...result.recommendations);
    });

    // Remove duplicates
    merged.keyTerms = Array.from(new Set(merged.keyTerms));
    merged.potentialRisks = Array.from(new Set(merged.potentialRisks));
    merged.importantClauses = Array.from(new Set(merged.importantClauses));
    merged.recommendations = merged.recommendations ? Array.from(new Set(merged.recommendations)) : [];

    merged.summary = `Analysis based on ${results.length} sections. ${results[0]?.summary || 'No summary available.'}`;

    return merged;
  } catch (error) {
    Sentry.captureException(error, {
      extra: { resultCount: results.length },
    });
    throw error instanceof ContractAnalysisError ? error :
      new ContractAnalysisError('Failed to merge analysis results', 'TEXT_PROCESSING_ERROR', error);
  } finally {
    mergeTransaction.finish();
  }
}

export async function analyzeContract(formData: FormData) {
  const transaction = Sentry.startTransaction({
    name: 'analyze_contract',
    op: 'contract.analyze',
  });

  try {
    const filename = formData.get("filename");
    Sentry.setContext("contract", {
      filename,
      timestamp: new Date().toISOString(),
    });

    if (!process.env.OPENAI_API_KEY) {
      throw new ContractAnalysisError("OpenAI API key not configured", "CONFIGURATION_ERROR");
    }

    const text = formData.get("text");
    if (!text || typeof text !== 'string' || text.length === 0) {
      throw new ContractAnalysisError("Invalid or empty document content", "INVALID_INPUT");
    }

    if (!filename || typeof filename !== 'string') {
      throw new ContractAnalysisError("No filename provided", "INVALID_INPUT");
    }

    const chunks = splitIntoChunks(text);
    if (chunks.length === 0) {
      throw new ContractAnalysisError("Document content too short", "INVALID_INPUT");
    }

    transaction.setData({
      chunkCount: chunks.length,
      textLength: text.length,
    });

    const analysisResults = await Promise.all(
      chunks.map((chunk, index) => analyzeChunk(chunk, index, chunks.length))
    );

    const mergedAnalysis = mergeAnalysisResults(analysisResults);

    return {
      ...mergedAnalysis,
      metadata: {
        analyzedAt: new Date().toISOString(),
        documentName: filename,
        modelVersion: "gpt-3.5-turbo-1106",
        totalChunks: chunks.length
      } as AnalysisMetadata,
    };
  } catch (error) {
    Sentry.captureException(error, {
      extra: {
        filename: formData.get("filename"),
        textLength: formData.get("text")?.toString().length,
      },
    });

    if (error instanceof ContractAnalysisError) {
      throw error;
    }
    
    if (error instanceof OpenAI.APIError) {
      throw new ContractAnalysisError(
        `OpenAI API error: ${error.message}`,
        'API_ERROR',
        error
      );
    }

    throw new ContractAnalysisError(
      `Failed to analyze contract: ${error instanceof Error ? error.message : 'Unknown error'}`,
      'UNKNOWN_ERROR',
      error
    );
  } finally {
    transaction.finish();
  }
}